---
permalink: /
title: "Lishuang Zhan &#124; 詹李双"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a Master student (since fall, 2021) and an incoming Ph.D student in [School of Informatics, Xiamen University](https://informatics.xmu.edu.cn/), advised by Prof. [Shihui Guo](https://www.humanplus.xyz/). My research focuses on natural human-computer interaction, flexible wearables, and multimodal sensing.

# Education
<table style="width:100%; border-collapse: collapse; border: none; font-size: 18px; line-height: 0.8;">
  <tr>
    <td style="width:15%; border: none;">2024-now</td>
    <td style="width:85%; border: none;">Xiamen University, Ph.D in Computer Science and Technology</td>
  </tr>
  <tr>
    <td style="width:15%; border: none;">2021-2024</td>
    <td style="width:85%; border: none;">Xiamen University, Master in Software Engineering</td>
  </tr>
  <tr>
    <td style="width:15%; border: none;">2017-2021</td>
    <td style="width:85%; border: none;">Xiamen University, Bachelor in Digital Media Technology</td>
  </tr>
</table>

# News
- 02/2024: Our paper [Loose Inertial Poser](https://openaccess.thecvf.com/content/CVPR2024/html/Zuo_Loose_Inertial_Poser_Motion_Capture_with_IMU-attached_Loose-Wear_Jacket_CVPR_2024_paper.html) on motion capture with IMU-attached loose-wear jacket is accepted to **CVPR 2024**.
- 10/2023: Our paper [TouchEditor](https://dl.acm.org/doi/abs/10.1145/3631454?af=R) on flexible text editing system is accepted to **Ubicomp/IMWUT 2024**.
- 04/2023: Our paper [Touch-and-Heal](https://dl.acm.org/doi/abs/10.1145/3596258) on data-driven affective computing is accepted to **Ubicomp/IMWUT 2023**.
- 01/2023: Our paper [Enable](https://ieeexplore.ieee.org/document/10161049) on human-robot-dog tactile interaction is accepted to **ICRA 2023**.
- 10/2022: Our paper [Handwriting Velcro](https://dl.acm.org/doi/10.1145/3569461) on flexible text input system is accepted to **Ubicomp/IMWUT 2023**.
- 08/2022: Our paper [Full-body](https://dl.acm.org/doi/10.1145/3564700) on sparse joint tracking is accepted to **Ubicomp/IMWUT 2023**.
- 10/2021: Our paper MSMC-ProVis on data processing and visualization won the **<span style="color: red;">Best Poster Paper</span>** on **ChinaVR 2021**.

# Publications

<table style="width:100%; border-collapse: collapse; border: none; font-size: 10px;">
  <tr>
    <td style="width:35%; border: none;"><img src="/images/cvpr_looseinertialposer.jpg" width="100%"></td>
    <td style="width:65%; border: none;">
      <strong><a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zuo_Loose_Inertial_Poser_Motion_Capture_with_IMU-attached_Loose-Wear_Jacket_CVPR_2024_paper.html">Loose Inertial Poser: Motion Capture with IMU-attached Loose-Wear Jacket</a></strong><br>
      Chengxu Zuo, Yiming Wang, <strong>Lishuang Zhan</strong>, Shihui Guo*, Xinyu Yi, Feng Xu, Yipeng Qin<br>
      <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024</em><br>
      Loose Inertial Poser is a novel motion capture solution with high wearing comfortableness by integrating four Inertial Measurement Units (IMUs) into a loose-wear jacket.
    </td>
  </tr>
</table>

<table style="width:100%; border-collapse: collapse; border: none; font-size: 10px;">
  <tr>
    <td style="width:35%; border: none;"><img src="/images/imwut_toucheditor.jpg" width="100%"></td>
    <td style="width:65%; border: none;">
      <strong><a href="https://dl.acm.org/doi/abs/10.1145/3631454?af=R">TouchEditor: Interaction Design and Evaluation of a Flexible Touchpad for Text Editing of Head-Mounted Displays in Speech-unfriendly Environments</a></strong><br>
      <strong>Lishuang Zhan</strong>, Tianyang Xiong, Hongwei Zhang, Shihui Guo*, Xiaowei Chen, Jiangtao Gong, Juncong Lin, Yipeng Qin<br>
      <em>Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (<strong>Ubicomp/IMWUT</strong>), 2024</em><br>
      TouchEditor is a novel text editing system for HMDs based on a flexible piezoresistive film sensor, supporting cursor positioning, text selection, text retyping and editing commands (i.e., Copy, Paste, Delete, etc.).
    </td>
  </tr>
</table>

<table style="width:100%; border-collapse: collapse; border: none; font-size: 10px;">
  <tr>
    <td style="width:35%; border: none;"><img src="/images/imwut_touchandheal.png" width="100%"></td>
    <td style="width:65%; border: none;">
      <strong><a href="https://dl.acm.org/doi/abs/10.1145/3596258">Touch-and-Heal: Data-driven Affective Computing in Tactile Interaction with Robotic Dog</a></strong><br>
      Shihui Guo*, <strong>Lishuang Zhan*</strong>, Yancheng Cao, Chen Zheng, Guyue Zhou, Jiangtao Gong<br>
      <em>Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (<strong>Ubicomp/IMWUT</strong>), 2023</em><br>
      We propose a data-driven affective computing system based on a biomimetic quadruped robot with large-format, high-density flexible pressure sensors, which can mimic the natural tactile interaction between humans and pet dogs.
    </td>
  </tr>
</table>

<table style="width:100%; border-collapse: collapse; border: none; font-size: 10px;">
  <tr>
    <td style="width:35%; border: none;"><img src="/images/icra_enable.png" width="100%"></td>
    <td style="width:65%; border: none;">
      <strong><a href="https://ieeexplore.ieee.org/document/10161049">Enable Natural Tactile Interaction for Robot Dog based on Large-format Distributed Flexible Pressure Sensors</a></strong><br>
      <strong>Lishuang Zhan</strong>, Yancheng Cao, Qitai Chen, Haole Guo, Jiasi Gao, Yiyue Luo, Shihui Guo, Guyue Zhou, Jiangtao Gong<br>
      <em>IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>), 2023</em><br>
      In this paper, we design and implement a set of large-format distributed flexible pressure sensors on a robot dog to enable natural human-robot tactile interaction.
    </td>
  </tr>
</table>

<table style="width:100%; border-collapse: collapse; border: none; font-size: 10px;">
  <tr>
    <td style="width:35%; border: none;"><img src="/images/tom_fullbody.png" width="100%"></td>
    <td style="width:65%; border: none;">
      <strong><a href="https://dl.acm.org/doi/10.1145/3564700">Full-body Human Motion Reconstruction with Sparse Joint Tracking Using Flexible Sensors</a></strong><br>
      Xiaowei Chen, Xiao Jiang, <strong>Lishuang Zhan</strong>, Shihui Guo*, Qunsheng Ruan, Guoliang Luo, Minghong Liao, Yipeng Qin<br>
      <em>ACM Transactions on Multimedia Computing, Communications and Applications (<strong>TOMMCCAP</strong>), 2023</em><br>
      In this work, we propose a novel framework to accurately predict human joint moving angles from signals of only four flexible sensors, thereby achieving human joint tracking in multi-degrees of freedom.
    </td>
  </tr>
</table>

<table style="width:100%; border-collapse: collapse; border: none; font-size: 10px;">
  <tr>
    <td style="width:35%; border: none;"><img src="/images/imwut_handwritingvelcro.png" width="100%"></td>
    <td style="width:65%; border: none;">
      <strong><a href="https://dl.acm.org/doi/10.1145/3569461">Handwriting Velcro: Endowing AR Glasses with Personalized and Posture-adaptive Text Input Using Flexible Touch Sensor</a></strong><br>
      Fengyi Fang, Hongwei Zhang, <strong>Lishuang Zhan</strong>, Shihui Guo*, Minying Zhang, Juncong Lin, Yipeng Qin, and Hongbo Fu<br>
      <em>Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (<strong>Ubicomp/IMWUT</strong>), 2023</em><br>
      Handwriting Velcro is a novel text input solution for AR glasses based on flexible touch sensors, which can easily stick to different body parts, thus endowing AR glasses with posture-adaptive handwriting input.
    </td>
  </tr>
</table>
